{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc562be",
   "metadata": {},
   "source": [
    "## **MULTIPLE LINEAR REGRESSION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0729d",
   "metadata": {},
   "source": [
    "## Let’s break down Multiple Linear Regression in a simple and easy way, like you're explaining it to someone new to data science.\n",
    "\n",
    "### 🔍 What is Multiple Linear Regression?\n",
    "##### Multiple Linear Regression (MLR) is a method used in statistics and machine learning to predict a numeric outcome (called the target) using two or more input features (called predictors or independent variables).\n",
    "\n",
    "#### Think of it like this:\n",
    "\n",
    "#### 💡 \"You’re trying to predict the price of a house based on its size, number of bedrooms, and distance from the city center.\"\n",
    "\n",
    "### 🏗️ The Formula (Don’t worry, we’ll simplify it!)\n",
    "##### Price=β0+β1⋅Size+β2⋅Bedrooms+β3⋅Distance+ε\n",
    "\n",
    "##### β₀: Intercept (the price when all other features are zero)\n",
    "\n",
    "##### β₁, β₂, β₃: Coefficients (they tell us how much the price changes when we increase each feature)\n",
    "\n",
    "##### ε: Error term (stuff we can’t explain)\n",
    "\n",
    "##### 💬 Real-life Analogy\n",
    "##### Imagine you’re a chef and you’re trying to predict how much customers will love your new dish. The score depends on:\n",
    "\n",
    "##### How spicy it is 🌶️\n",
    "\n",
    "##### How sweet it is 🍯\n",
    "\n",
    "##### How salty it is 🧂\n",
    "\n",
    "##### Each of these ingredients contributes in a different way to the final taste. You want to find the right weights (coefficients) for each ingredient that best explain the customers' reactions. That’s exactly what MLR does!\n",
    "\n",
    "#### ✅ What MLR Does:\n",
    "##### Fits a line (or plane/hyperplane) through the data.\n",
    "\n",
    "##### Finds the best combination of input features to predict the output.\n",
    "\n",
    "##### Minimizes the difference between the predicted and actual values (called the residuals).\n",
    "\n",
    "##### 📊 Example with Data\n",
    "#### Let’s say we have this table:\n",
    "\n",
    "####  Size (sq ft)   \tBedrooms\t Distance to city (km)\t      Price (Ksh)\n",
    "####  1000\t               2\t             5\t                       5M\n",
    "####  1200\t               3\t             3\t                       6.2M\n",
    "####  1500\t               3\t             2\t                       7.1M\n",
    "\n",
    "#### MLR will learn how much Size, Bedrooms, and Distance each contribute to the final Price, then use that to predict prices for new houses.\n",
    "\n",
    "#### 📦 Tools to Use in Python:\n",
    "#### sklearn.linear_model.LinearRegression\n",
    "\n",
    "#### statsmodels.api.OLS (for more statistical details)\n",
    "\n",
    "#### 🎯 Why It’s Powerful\n",
    "#### Helps you understand how much each feature matters.\n",
    "\n",
    "#### Can be used for forecasting, business planning, risk modeling, and more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966ab94",
   "metadata": {},
   "source": [
    "## Let go through a short Python code example using scikit-learn to fit a Multiple Linear Regression model, and then show you how to interpret the coefficients.\n",
    "\n",
    "#### 🏠 Example: Predicting House Price\n",
    "##### We’ll use a small dataset where we want to predict the price of a house based on:\n",
    "\n",
    "##### size in square feet\n",
    "\n",
    "##### bedrooms\n",
    "\n",
    "##### distance to city in kilometers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ed319",
   "metadata": {},
   "source": [
    "### ✅ Step-by-Step Code;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb283b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept (β₀): 3.274999999999988\n",
      "Coefficients (β₁, β₂, β₃): [ 0.00225  0.3     -0.225  ]\n",
      "Predicted Price (in millions): 7.324999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. Sample data\n",
    "data = {\n",
    "    'size': [1000, 1200, 1500, 1800],\n",
    "    'bedrooms': [2, 3, 3, 4],\n",
    "    'distance': [5, 3, 2, 1],\n",
    "    'price': [5.0, 6.2, 7.1, 8.3]  # in millions\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Features (X) and Target (y)\n",
    "X = df[['size', 'bedrooms', 'distance']]\n",
    "y = df['price']\n",
    "\n",
    "# 3. Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# 4. Show coefficients\n",
    "print(\"Intercept (β₀):\", model.intercept_)\n",
    "print(\"Coefficients (β₁, β₂, β₃):\", model.coef_)\n",
    "\n",
    "# 5. Predict the price of a new house\n",
    "new_house = [[1600, 3, 2]]\n",
    "predicted_price = model.predict(new_house)\n",
    "print(\"Predicted Price (in millions):\", predicted_price[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff6e1d",
   "metadata": {},
   "source": [
    "### 📊 Output Interpretation (Example)\n",
    "##### Let’s say the output is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686e385",
   "metadata": {},
   "source": [
    "##### Intercept (β₀): 1.2\n",
    "##### Coefficients (β₁, β₂, β₃): [0.003, 0.5, -0.4]\n",
    "##### Predicted Price (in millions): 7.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7c7c5",
   "metadata": {},
   "source": [
    "#### This means:\n",
    "\n",
    "##### Intercept (β₀ = 1.2): If size, bedrooms, and distance were all 0, the model predicts the price as 1.2M (not realistic but mathematically valid).\n",
    "\n",
    "##### Size (β₁ = 0.003): For each extra square foot, price increases by 3,000 Ksh (since 0.003M = 3K).\n",
    "\n",
    "##### Bedrooms (β₂ = 0.5): Each additional bedroom adds 0.5M to the price.\n",
    "\n",
    "##### Distance (β₃ = -0.4): Every 1 km farther from the city reduces price by 0.4M.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f193df6",
   "metadata": {},
   "source": [
    "### 💡 Insights;\n",
    "\n",
    "##### Coefficients tell you how much each feature affects the price.\n",
    "\n",
    "##### Positive = increases price, Negative = decreases price.\n",
    "\n",
    "#### You can use it to make predictions and understand relationships in your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d48ee25",
   "metadata": {},
   "source": [
    "\n",
    " ### Let's now do the same example using statsmodels, which gives you a detailed statistical summary, including:\n",
    "\n",
    "### Coefficients\n",
    "\n",
    "#### R² score\n",
    "\n",
    "#### p-values (to check if features are significant)\n",
    "\n",
    "#### Confidence intervals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ef7a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Thu, 03 Jul 2025   Prob (F-statistic):                nan\n",
      "Time:                        12:29:09   Log-Likelihood:                 111.02\n",
      "No. Observations:                   4   AIC:                            -214.0\n",
      "Df Residuals:                       0   BIC:                            -216.5\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2750        inf          0        nan         nan         nan\n",
      "size           0.0022        inf          0        nan         nan         nan\n",
      "bedrooms       0.3000        inf          0        nan         nan         nan\n",
      "distance      -0.2250        inf         -0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   0.027\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.375\n",
      "Skew:                           0.168   Prob(JB):                        0.829\n",
      "Kurtosis:                       1.537   Cond. No.                     4.09e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.09e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python313\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python313\\site-packages\\statsmodels\\regression\\linear_model.py:1795: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python313\\site-packages\\statsmodels\\regression\\linear_model.py:1795: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python313\\site-packages\\statsmodels\\regression\\linear_model.py:1717: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 1. Sample data\n",
    "data = {\n",
    "    'size': [1000, 1200, 1500, 1800],\n",
    "    'bedrooms': [2, 3, 3, 4],\n",
    "    'distance': [5, 3, 2, 1],\n",
    "    'price': [5.0, 6.2, 7.1, 8.3]  # in millions\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Define X and y\n",
    "X = df[['size', 'bedrooms', 'distance']]\n",
    "X = sm.add_constant(X)  # Adds intercept term (β₀)\n",
    "y = df['price']\n",
    "\n",
    "# 3. Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# 4. View summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862dfa3",
   "metadata": {},
   "source": [
    "### 🧠 Interpretation:\n",
    "#### coef: These are the same as in sklearn (β values).\n",
    "\n",
    "#### P>|t|: This is the p-value.\n",
    "\n",
    "#### If it's < 0.05, the feature is statistically significant (i.e., it truly impacts price).\n",
    "\n",
    "#### R-squared (R²): 0.998 means the model explains 99.8% of the variation in house price — excellent fit (though suspiciously high on small data).\n",
    "\n",
    "#### Confidence Interval [0.025, 0.975]: Range in which the true coefficient likely falls.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dc228b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 🧠 When to Use statsmodels vs sklearn\n",
    "#### Purpose\t                        -    Use This\n",
    "#### Predict new values                  -     \tsklearn\n",
    "#### Understand model statistically       -   \tstatsmodels\n",
    "#### Get p-values, CI, R²\t               -     statsmodels\n",
    "#### Fast prediction pipelines\t           -     sklearn\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
